<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
            "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>

<META http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<META name="GENERATOR" content="hevea 1.10">
<LINK rel="stylesheet" type="text/css" href="thinkstats.css">
<TITLE>Correlation</TITLE>
</HEAD>
<BODY >
<A HREF="thinkstats009.html"><IMG SRC="back.png" ALT="Previous"></A>
<A HREF="index.html"><IMG SRC="up.png" ALT="Up"></A>
<A HREF="thinkstats011.html"><IMG SRC="next.png" ALT="Next"></A>
<HR>
<table cellpadding=10>

<tr>

<td valign="top" width=100 bgcolor="#1B82E6">
</td>

<td valign="top" width=600>

<p>This HTML version of is provided for convenience, but it
is not the best format for the book.  In particular, some of the
symbols are not rendered correctly.

<p>You might prefer to read
the <a href="http://thinkstats.com/thinkstats.pdf">PDF version</a>, or
you can buy a hardcopy 
<a href="http://www.lulu.com/product/paperback/think-stats/12443331">here</a>.
<H1 CLASS="chapter"><A NAME="htoc83">Chapter&#XA0;9</A>&#XA0;&#XA0;Correlation</H1><H2 CLASS="section"><A NAME="toc77"></A><A NAME="htoc84">9.1</A>&#XA0;&#XA0;Standard scores</H2><P>In this chapter we look at relationships between variables. For
example, we have a sense that height is related to weight; people who
are taller tend to be heavier. <B>Correlation</B> is a description of
this kind of relationship.
<A NAME="@default958"></A></P><P>A challenge in measuring correlation is that the variables we want
to compare might not be expressed in the same units. For example, height
might be in centimeters and weight in kilograms. And even if they are
in the same units, they come from different distributions.
<A NAME="@default959"></A></P><P>There are two common solutions to these problems:</P><OL CLASS="enumerate" type=1><LI CLASS="li-enumerate">Transform all values to <B>standard scores</B>. This leads to
the Pearson coefficient of correlation.
<A NAME="@default960"></A>
<A NAME="@default961"></A>
<A NAME="@default962"></A>
<A NAME="@default963"></A></LI><LI CLASS="li-enumerate">Transform all values to their percentile ranks. This
leads to the Spearman coefficient.
<A NAME="@default964"></A>
<A NAME="@default965"></A></LI></OL><P>If <I>X</I>&#XA0;is a series of values, <I>x<SUB>i</SUB></I>, we can convert to standard
scores by subtracting the mean and dividing by the standard deviation:
z<I><SUB>i</SUB></I>&#XA0;=&#XA0;(x<I><SUB>i</SUB></I>&#XA0;&#X2212;&#XA0;&#XB5;) / &#X3C3;.
<A NAME="@default966"></A>
<A NAME="@default967"></A></P><P>The numerator is a deviation: the distance from the mean. Dividing by
&#X3C3;&#XA0;<B>normalizes</B> the deviation, so the values of <I>Z</I>&#XA0;are
dimensionless (no units) and their distribution has mean 0 and
variance 1.
<A NAME="@default968"></A>
<A NAME="@default969"></A>
<A NAME="@default970"></A>
<A NAME="@default971"></A>
<A NAME="@default972"></A>
<A NAME="@default973"></A></P><P>If <I>X</I>&#XA0;is normally-distributed, so is <I>Z</I>; but if <I>X</I>&#XA0;is skewed or has
outliers, so does <I>Z</I>. In those cases it is more robust to use
percentile ranks. If <I>R</I>contains the percentile ranks of the
values in <I>X</I>, the distribution of <I>R</I>is uniform between 0 and 100,
regardless of the distribution of <I>X</I>.
<A NAME="@default974"></A>
<A NAME="@default975"></A>
<A NAME="@default976"></A></P><H2 CLASS="section"><A NAME="toc78"></A><A NAME="htoc85">9.2</A>&#XA0;&#XA0;Covariance</H2><P>
<A NAME="@default977"></A>
<A NAME="@default978"></A></P><P><B>Covariance</B> is a measure of the tendency of two variables
to vary together. If we have two series, <I>X</I>&#XA0;and <I>Y</I>, their
deviations from the mean are</P><P>&#XA0;&#XA0; <I>dx<SUB>i</SUB></I> = <I>x<SUB>i</SUB></I>&#XA0;&#X2212;&#XA0;&#XB5;<I><SUB>X</SUB></I> </P><P>&#XA0;&#XA0; <I>dy<SUB>i</SUB></I> = <I>y<SUB>i</SUB></I>&#XA0;&#X2212;&#XA0;&#XB5;<I><SUB>Y</SUB></I> </P><P>where &#XB5;<I><SUB>X</SUB></I> is the mean of <I>X</I>&#XA0;and &#XB5;<I><SUB>Y</SUB></I> is the mean of <I>Y</I>.
If <I>X</I>&#XA0;and <I>Y</I>&#XA0;vary together, their deviations tend to have the same
sign.</P><P>If we multiply them together, the product is positive when the
deviations have the same sign and negative when they have the opposite
sign. So adding up the products gives a measure of the tendency to
vary together.</P><P>Covariance is the mean of these products:
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><I>Cov</I>(<I>X</I>,<I>Y</I>)&#XA0;=&#XA0;</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
</TABLE></TD><TD CLASS="dcell">&#XA0;<FONT SIZE=6>&#X2211;</FONT><I>dx<SUB>i</SUB></I>&#XA0;<I>dy<SUB>i</SUB></I>&#XA0;</TD></TR>
</TABLE><P>
where <I>n</I>&#XA0;is the length of the two series (they have to be the same
length).</P><P>Covariance is useful in some computations, but
it is seldom reported as a summary statistic because it is hard to
interpret. Among other problems, its units are the product of the
units of <I>X</I>&#XA0;and <I>Y</I>. So the covariance of weight and height might be
in units of kilogram-meters, which doesn&#X2019;t mean much.</P><DIV CLASS="theorem"><B>Exercise&#XA0;1</B>&#XA0;&#XA0;<EM>
Write a function called <TT>Cov</TT> that takes two lists
and computes their covariance. To test your function, compute
the covariance of a list with itself and confirm that
Cov(<I>X</I>, <I>X</I>)&#XA0;=&#XA0;Var(<I>X</I>).</EM><P><EM>You can download a solution from
<TT>http://thinkstats.com/correlation.py</TT>.
</EM><A NAME="@default979"></A></P></DIV><H2 CLASS="section"><A NAME="toc79"></A><A NAME="htoc86">9.3</A>&#XA0;&#XA0;Correlation</H2><P>
<A NAME="@default980"></A>
<A NAME="@default981"></A></P><P>One solution to this problem is to divide the deviations by &#X3C3;,
which yields standard scores, and compute the product of standard scores:
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><I>p<SUB>i</SUB></I>&#XA0;=&#XA0;</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">(<I>x<SUB>i</SUB></I>&#XA0;&#X2212;&#XA0;&#XB5;<I><SUB>X</SUB></I>)</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">&#X3C3;<I><SUB>X</SUB></I></TD></TR>
</TABLE></TD><TD CLASS="dcell">&#XA0;</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">(<I>y<SUB>i</SUB></I>&#XA0;&#X2212;&#XA0;&#XB5;<I><SUB>Y</SUB></I>)</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">&#X3C3;<I><SUB>Y</SUB></I></TD></TR>
</TABLE></TD><TD CLASS="dcell">&#XA0;</TD></TR>
</TABLE><P>
The mean of these products is
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">&#X3C1;&#XA0;=&#XA0;</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
</TABLE></TD><TD CLASS="dcell">&#XA0;<FONT SIZE=6>&#X2211;</FONT><I>p<SUB>i</SUB></I>&#XA0;</TD></TR>
</TABLE><P>
Or we can rewrite &#X3C1;&#XA0;by factoring out &#X3C3;<I><SUB>X</SUB></I> and
&#X3C3;<I><SUB>Y</SUB></I>:
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">&#X3C1;&#XA0;=&#XA0;</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>Cov</I>(<I>X</I>,<I>Y</I>)</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">&#X3C3;<I><SUB>X</SUB></I>&#XA0;&#X3C3;<I><SUB>Y</SUB></I></TD></TR>
</TABLE></TD><TD CLASS="dcell">&#XA0;</TD></TR>
</TABLE><P>
This value is called <B>Pearson&#X2019;s correlation</B> after Karl Pearson,
an influential early statistician. It is easy to compute and easy to
interpret. Because standard scores are dimensionless, so is &#X3C1;.
<A NAME="@default982"></A>
<A NAME="@default983"></A>
<A NAME="@default984"></A></P><P>Pearson&#X2019;s correlation is always between -1 and +1 (including both).
The magnitude indicates the strength of the correlation. If
&#X3C1;&#XA0;=&#XA0;1 the variables are perfectly correlated, which means that if
you know one, you can make a perfect prediction about the other. The
same is true if &#X3C1;&#XA0;=&#XA0;&#X2212;1. It means that the variables
are negatively correlated, but for purposes of prediction, a
negative correlation is just as good as a positive one.
<A NAME="@default985"></A></P><P>Most correlation in the real world is not perfect, but it
is still useful. For example, if you know someone&#X2019;s height, you might
be able to guess their weight. You might not get it exactly right, but
your guess will be better than if you didn&#X2019;t know the height.
Pearson&#X2019;s correlation is a measure of how much better.</P><P>So if &#X3C1;&#XA0;=&#XA0;0, does that mean there is no
relationship between the variables? Unfortunately, no. Pearson&#X2019;s
correlation only measures <EM>linear</EM> relationships. If there&#X2019;s a
nonlinear relationship, &#X3C1;&#XA0;understates the strength of the
dependence.
<A NAME="@default986"></A></P><BLOCKQUOTE CLASS="figure"><DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV>
<DIV CLASS="center"><IMG SRC="thinkstats018.png"></DIV>
<DIV CLASS="caption"><TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=top ALIGN=left>Figure 9.1: Examples of datasets with a range of correlations.</TD></TR>
</TABLE></DIV>
<A NAME="corr_examples"></A>
<DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV></BLOCKQUOTE><P>Figure&#XA0;<A HREF="#corr_examples">9.1</A> is from
<TT>http://wikipedia.org/wiki/Correlation_and_dependence</TT>. It shows
scatterplots and correlation coefficients for several
carefully-constructed datasets.
<A NAME="@default987"></A>
<A NAME="@default988"></A>
<A NAME="@default989"></A></P><P>The top row shows linear relationships with a range of correlations;
you can use this row to get a sense of what different values of
&#X3C1;&#XA0;look like. The second row shows perfect correlations with a
range of slopes, which demonstrates that correlation is unrelated to
slope (we&#X2019;ll talk about estimating slope soon). The third row shows
variables that are clearly related, but because the relationship is
non-linear, the correlation coefficient is 0.</P><P>The moral of this story is that you should always look at a scatterplot of
your data before blindly computing a correlation coefficient.
<A NAME="@default990"></A>
<A NAME="@default991"></A></P><DIV CLASS="theorem"><B>Exercise&#XA0;2</B>&#XA0;&#XA0;<EM>
Write a function called <TT>Corr</TT> that takes two lists and
computes their correlation. Hint: use <TT>thinkstats.Var</TT> and
the <TT>Cov</TT> function you wrote in the previous exercise.
</EM><A NAME="@default992"></A>
<A NAME="@default993"></A><P><EM>To test your function, compute the covariance of a list with itself
and confirm that Corr(<I>X</I>, <I>X</I>) is 1. You can download a solution
from <TT>http://thinkstats.com/correlation.py</TT>.
</EM><A NAME="@default994"></A></P></DIV><H2 CLASS="section"><A NAME="toc80"></A><A NAME="htoc87">9.4</A>&#XA0;&#XA0;Making scatterplots in pyplot</H2><P>
<A NAME="@default995"></A>
<A NAME="@default996"></A>
<A NAME="@default997"></A></P><BLOCKQUOTE CLASS="figure"><DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV>
<DIV CLASS="center"><IMG SRC="thinkstats019.png"></DIV>
<DIV CLASS="caption"><TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=top ALIGN=left>Figure 9.2: Simple scatterplot of weight versus height for the respondents
in the BRFSS.</TD></TR>
</TABLE></DIV>
<A NAME="scatterplot1"></A>
<DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV></BLOCKQUOTE><BLOCKQUOTE CLASS="figure"><DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV>
<DIV CLASS="center"><IMG SRC="thinkstats020.png"></DIV>
<DIV CLASS="caption"><TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=top ALIGN=left>Figure 9.3: Scatterplot with jittered data.</TD></TR>
</TABLE></DIV>
<A NAME="scatterplot2"></A>
<DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV></BLOCKQUOTE><BLOCKQUOTE CLASS="figure"><DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV>
<DIV CLASS="center"><IMG SRC="thinkstats021.png"></DIV>
<DIV CLASS="caption"><TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=top ALIGN=left>Figure 9.4: Scatterplot with jittering and transparency.</TD></TR>
</TABLE></DIV>
<A NAME="scatterplot3"></A>
<DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV></BLOCKQUOTE><BLOCKQUOTE CLASS="figure"><DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV>
<DIV CLASS="center"><IMG SRC="thinkstats022.png"></DIV>
<DIV CLASS="caption"><TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=top ALIGN=left>Figure 9.5: Scatterplot with binned data using <TT>pyplot.hexbin</TT>.</TD></TR>
</TABLE></DIV>
<A NAME="scatterplot4"></A>
<DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV></BLOCKQUOTE><P>
<A NAME="@default998"></A>
<A NAME="@default999"></A></P><P>The simplest way to check for a relationship between two variables
is a scatterplot, but making a good scatterplot is not always easy.
As an example, I&#X2019;ll plot weight versus height for the respondents
in the BRFSS (see Section&#XA0;<A HREF="thinkstats005.html#lognormal">4.5</A>). <TT>pyplot</TT> provides
a function named <TT>scatter</TT> that makes scatterplots:
</P><PRE CLASS="verbatim">import matplotlib.pyplot as pyplot
pyplot.scatter(heights, weights)
</PRE><P>Figure&#XA0;<A HREF="#scatterplot1">9.2</A> shows the result. Not surprisingly, it
looks like there is a positive correlation: taller people tend to be
heavier. But this is not the best representation of the data, because
the data are packed into columns. The problem is that the heights
were rounded to the nearest inch, converted to centimeters, and
then rounded again. Some information is lost in translation.
<A NAME="@default1000"></A>
<A NAME="@default1001"></A>
<A NAME="@default1002"></A></P><P>We can&#X2019;t get that information back, but we can minimize the effect on
the scatterplot by <B>jittering</B> the data, which means adding random
noise to reverse the effect of rounding off. Since these measurements
were rounded to the nearest inch, they can be off by up to 0.5 inches or
1.3 cm. So I added uniform noise in the range &#X2212;1.3 to 1.3:
<A NAME="@default1003"></A>
<A NAME="@default1004"></A>
<A NAME="@default1005"></A>
</P><PRE CLASS="verbatim">jitter = 1.3
heights = [h + random.uniform(-jitter, jitter) for h in heights]
</PRE><P>Figure&#XA0;<A HREF="#scatterplot2">9.3</A> shows the result. Jittering the data makes
the shape of the relationship clearer. In general you should only jitter
data for purposes of visualization and avoid using jittered data
for analysis.</P><P>Even with jittering, this is not the best way to represent the data.
There are many overlapping points, which hides data
in the dense parts of the figure and gives disproportionate emphasis
to outliers.
<A NAME="@default1006"></A></P><P>We can solve that with the <TT>alpha</TT> parameter, which makes
the points partly transparent:
</P><PRE CLASS="verbatim">pyplot.scatter(heights, weights, alpha=0.2)
</PRE><P>Figure&#XA0;<A HREF="#scatterplot3">9.4</A> shows the result. Overlapping data
points look darker, so darkness is proportional to density. In this
version of the plot we can see an apparent artifact: a horizontal line
near 90 kg or 200 pounds. Since this data is based on self-reports in
pounds, the most likely explanation is some responses were rounded off
(possibly down).</P><P>Using transparency works well for moderate-sized datasets, but this
figure only shows the first 1000 records in the BRFSS, out of a total
of 414509.
<A NAME="@default1007"></A>
<A NAME="@default1008"></A></P><P>To handle larger datasets, one option is a hexbin plot, which divides
the graph into hexagonal bins and colors each bin according to how many
data points fall in it. <TT>pyplot</TT> provides a function called 
<TT>hexbin</TT>:
</P><PRE CLASS="verbatim">pyplot.hexbin(heights, weights, cmap=matplotlib.cm.Blues)
</PRE><P>Figure&#XA0;<A HREF="#scatterplot4">9.5</A> shows the result with a blue colormap.
An advantage of a hexbin is that it shows the shape of the relationship
well, and it is efficient for large datasets. A drawback is that
it makes the outliers invisible.
<A NAME="@default1009"></A>
<A NAME="@default1010"></A></P><P>The moral of this story is that it is
not easy to make a scatterplot that is not potentially misleading.
You can download the code for these figures from
<TT>http://thinkstats.com/brfss_scatter.py</TT>.
<A NAME="@default1011"></A></P><H2 CLASS="section"><A NAME="toc81"></A><A NAME="htoc88">9.5</A>&#XA0;&#XA0;Spearman&#X2019;s rank correlation</H2><P>Pearson&#X2019;s correlation works well if the relationship between variables
is linear and if the variables are roughly normal. But it is not
robust in the presence of outliers.
<A NAME="@default1012"></A>
<A NAME="@default1013"></A>
<A NAME="@default1014"></A>
<A NAME="@default1015"></A>
<A NAME="@default1016"></A>
<A NAME="@default1017"></A>
<A NAME="@default1018"></A></P><P>Anscombe&#X2019;s quartet demonstrates this effect; it contains four data
sets with the same correlation. One is a linear relation with random
noise, one is a non-linear relation, one is a perfect relation with an
outlier, and one has no relation except an artifact caused by an
outlier. You can read more about it at
<TT>http://wikipedia.org/wiki/Anscombe's_quartet</TT>.
<A NAME="@default1019"></A></P><P>Spearman&#X2019;s rank correlation is an alternative that mitigates the
effect of outliers and skewed distributions. To compute Spearman&#X2019;s
correlation, we have to compute the <B>rank</B> of each value, which is its
index in the sorted sample. For example, in the sample {7, 1, 2, 5}
the rank of the value 5 is 3, because it appears third if we sort
the elements. Then we compute Pearson&#X2019;s correlation for the ranks.</P><P>An alternative to Spearman&#X2019;s is to apply a transform that makes the
data more nearly normal, then compute Pearson&#X2019;s correlation for the
transformed data. For example, if the data are approximately
lognormal, you could take the log of each value and compute the
correlation of the logs.
<A NAME="@default1020"></A>
<A NAME="@default1021"></A></P><DIV CLASS="theorem"><B>Exercise&#XA0;3</B>&#XA0;&#XA0;<EM>
Write a function that takes a sequence and returns a list that
contains the rank for each element. For example, if the sequence is
{7, 1, 2, 5}, the result should be { 4, 1, 2, 3}.</EM><P><EM>If the same value appears more than once, the strictly correct
solution is to assign each of them the average of their ranks. But if
you ignore that and assign them ranks in arbitrary order, the error is
usually small.</EM></P><P><EM>Write a function that takes two sequences (with the same length) and
computes their Spearman rank coefficient. You can download a solution
from <TT>http://thinkstats.com/correlation.py</TT>.
</EM><A NAME="@default1022"></A>
<A NAME="@default1023"></A>
<A NAME="@default1024"></A></P></DIV><DIV CLASS="theorem"><B>Exercise&#XA0;4</B>&#XA0;&#XA0;<EM>
Download <TT>http://thinkstats.com/brfss.py</TT> and
<TT>http://thinkstats.com/brfss_scatter.py</TT>. Run them and confirm that you
can read the BRFSS data and generate scatterplots.
</EM><A NAME="@default1025"></A>
<A NAME="@default1026"></A>
<A NAME="@default1027"></A>
<A NAME="@default1028"></A><P><EM>Comparing the scatterplots to Figure&#XA0;<A HREF="#corr_examples">9.1</A>, what value
do you expect for Pearson&#X2019;s correlation? What value do you get?
</EM><A NAME="@default1029"></A>
<A NAME="@default1030"></A>
<A NAME="@default1031"></A>
<A NAME="@default1032"></A>
<A NAME="@default1033"></A></P><P><EM>Because the distribution of adult weight is lognormal, there are
outliers that affect the correlation. Try plotting
log(weight) versus height, and compute Pearson&#X2019;s
correlation for the transformed variable.</EM></P><P><EM>Finally, compute Spearman&#X2019;s rank correlation for weight and height.
Which coefficient do you think is the best measure of the strength of
the relationship? You can download a solution from
<TT>http://thinkstats.com/brfss_corr.py</TT>.
</EM><A NAME="@default1034"></A></P></DIV><H2 CLASS="section"><A NAME="toc82"></A><A NAME="htoc89">9.6</A>&#XA0;&#XA0;Least squares fit</H2><P>Correlation coefficients measure the strength and sign of a
relationship, but not the slope. There are several ways to estimate
the slope; the most common is a <B>linear least squares fit</B>. A
&#X201C;linear fit&#X201D; is a line intended to model the relationship between
variables. A &#X201C;least squares&#X201D; fit is one that minimizes the mean
squared error (MSE) between the line and the data<SUP><A NAME="text26" HREF="#note26">1</A></SUP>.
<A NAME="@default1035"></A>
<A NAME="@default1036"></A>
<A NAME="@default1037"></A>
<A NAME="@default1038"></A></P><P>Suppose we have a sequence of points, <I>Y</I>, that we want to express as a
function of another sequence <I>X</I>. If there is a linear relationship
between <I>X</I>&#XA0;and <I>Y</I>&#XA0;with intercept &#X3B1;&#XA0;and slope &#X3B2;, we
expect each <I>y<SUB>i</SUB></I> to be roughly &#X3B1;&#XA0;+ &#X3B2;&#XA0;<I>x<SUB>i</SUB></I>.
<A NAME="@default1039"></A></P><P>But unless the correlation is perfect, this prediction is only
approximate. The deviation, or <B>residual</B>, is </P><P>&#XA0;&#XA0; &#X3B5;<I><SUB>i</SUB></I>&#XA0;=&#XA0;(&#X3B1;&#XA0;+&#XA0;&#X3B2;<I>x<SUB>i</SUB></I>)&#XA0;&#X2212;&#XA0;<I>y<SUB>i</SUB></I> </P><P>The residual might be due to random factors like measurement error,
or non-random factors that are unknown. For example, if we are
trying to predict weight as a function of height, unknown factors
might include diet, exercise, and body type.
<A NAME="@default1040"></A>
<A NAME="@default1041"></A></P><P>If we get the parameters &#X3B1;&#XA0;and &#X3B2;&#XA0;wrong, the residuals
get bigger, so it makes intuitive sense that the parameters we want
are the ones that minimize the residuals.</P><P>As usual, we could minimize the absolute value of the
residuals, or their squares, or their cubes, etc. The most common
choice is to minimize the sum of squared residuals
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">&#X3B1;,&#XA0;&#X3B2;</TD></TR>
</TABLE></TD><TD CLASS="dcell">&#XA0;<FONT SIZE=6>&#X2211;</FONT>&#X3B5;<I><SUB>i</SUB></I><SUP>2</SUP>&#XA0;</TD></TR>
</TABLE><P>
Why? There are three good reasons and one bad one:</P><UL CLASS="itemize"><LI CLASS="li-itemize">Squaring has the obvious feature of treating positive and
negative residuals the same, which is usually what we want.</LI><LI CLASS="li-itemize">Squaring gives more weight to large residuals, but not
so much weight that the largest residual always dominates.</LI><LI CLASS="li-itemize">If the residuals are independent of <I>x</I>, random, and normally
distributed with &#XB5;&#XA0;=&#XA0;0 and constant (but unknown) &#X3C3;, then
the least squares fit is also the maximum likelihood estimator of
&#X3B1;&#XA0;and &#X3B2;.<SUP><A NAME="text27" HREF="#note27">2</A></SUP>
<A NAME="@default1042"></A>
<A NAME="@default1043"></A></LI><LI CLASS="li-itemize">The values of &#X3B1; and &#X3B2; that minimize
the squared residuals can be computed efficiently.</LI></UL><P>That last reason made sense when computational efficiency was more
important than choosing the method most appropriate to the problem
at hand. That&#X2019;s no longer the case, so it is worth considering
whether squared residuals are the right thing to minimize.
<A NAME="@default1044"></A></P><P>For example, if you are using values of <I>X</I>&#XA0;to predict values of <I>Y</I>,
guessing too high might be better (or worse) than guessing too low.
In that case you might want to compute some cost function,
cost(&#X3B5;<I><SUB>i</SUB></I>), and minimize total cost.
<A NAME="@default1045"></A></P><P>However, computing a least squares fit is quick, easy and often good
enough, so here&#X2019;s how:</P><OL CLASS="enumerate" type=1><LI CLASS="li-enumerate">Compute the sample means, <SPAN style="text-decoration:overline">x</SPAN>&#XA0;and &#X233;, the variance
of <I>X</I>, and the covariance of <I>X</I>&#XA0;and <I>Y</I>.</LI><LI CLASS="li-enumerate">The estimated slope is
<TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">&#X3B2;&#XA0;=&#XA0;</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>Cov</I>(<I>X</I>,<I>Y</I>)</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>Var</I>(<I>X</I>)</TD></TR>
</TABLE></TD><TD CLASS="dcell">&#XA0;</TD></TR>
</TABLE>
</LI><LI CLASS="li-enumerate">And the intercept is
<TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">&#X3B1;&#XA0;=&#XA0;&#X233;&#XA0;&#X2212;&#XA0;&#X3B2;&#XA0;<SPAN style="text-decoration:overline">x</SPAN>&#XA0;</TD></TR>
</TABLE>
</LI></OL><P>To see how this is derived, you can read
<TT>http://wikipedia.org/wiki/Numerical_methods_for_linear_least_squares</TT>.</P><DIV CLASS="theorem"><B>Exercise&#XA0;5</B>&#XA0;&#XA0;<EM>
Write a function named <TT>LeastSquares</TT> that takes <I>X</I>&#XA0;and <I>Y</I>&#XA0;and
computes &#X3B1; and &#X3B2;. You can download a
solution from <TT>http://thinkstats.com/correlation.py</TT>. </EM><A NAME="@default1046"></A></DIV><DIV CLASS="theorem"><B>Exercise&#XA0;6</B>&#XA0;&#XA0;<EM>
Using the data from the BRFSS again, compute the linear least squares
fit for log(weight) versus height. You can download a
solution from <TT>http://thinkstats.com/brfss_corr.py</TT>.
</EM><A NAME="@default1047"></A>
<A NAME="@default1048"></A>
<A NAME="@default1049"></A></DIV><DIV CLASS="theorem"><B>Exercise&#XA0;7</B>&#XA0;&#XA0;<EM>
The distribution of wind speeds in a given location determines the
wind power density, which is an upper bound on the average power that
a wind turbine at that location can generate. According to some
sources, empirical distributions of wind speed are well modeled by a
Weibull distribution (see
<TT>http://wikipedia.org/wiki/Wind_power#Distribution_of_wind_speed</TT>).
</EM><A NAME="@default1050"></A>
<A NAME="@default1051"></A>
<A NAME="@default1052"></A>
<A NAME="@default1053"></A>
<A NAME="@default1054"></A><P><EM>To evaluate whether a location is a viable site for a wind turbine,
you can set up an anemometer to measure wind speed for a period of
time. But it is hard to measure the tail of the wind speed distribution
accurately because, by definition, events in the tail don&#X2019;t happen
very often.
</EM><A NAME="@default1055"></A></P><P><EM>One way to address this problem is to use measurements to estimate the
parameters of a Weibull distribution, then integrate over the
continuous PDF to compute wind power density.
</EM><A NAME="@default1056"></A></P><P><EM>To estimate the parameters of a Weibull distribution, we can use the
transformation from Exercise&#XA0;<A HREF="thinkstats005.html#weibull">6</A> and then use a linear fit
to find the slope and intercept of the transformed data.</EM></P><P><EM>Write a function that takes a sample from a Weibull distribution and
estimates its parameters.</EM></P><P><EM>Now write a function that takes the parameters of a Weibull distribution
of wind speed and computes average wind power density (you might have
to do some research for this part).</EM></P></DIV><H2 CLASS="section"><A NAME="toc83"></A><A NAME="htoc90">9.7</A>&#XA0;&#XA0;Goodness of fit</H2><P>
<A NAME="@default1057"></A>
<A NAME="@default1058"></A></P><P>Having fit a linear model to the data, we might want to know how good
it is. Well, that depends on what it&#X2019;s for. One way to evaluate a
model is its predictive power.</P><P>In the context of prediction, the quantity we are trying to guess is
called a <B>dependent variable</B> and the quantity we are using to
make the guess is called an <B>explanatory</B> or <B>independent
variable</B>.
<A NAME="@default1059"></A>
<A NAME="@default1060"></A>
<A NAME="@default1061"></A>
<A NAME="@default1062"></A></P><P>To measure the predictive power of a model, we can compute the <B>coefficient of determination</B>, more commonly known as &#X201C;R-squared&#X201D;:
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><I>R</I><SUP>2</SUP>&#XA0;=&#XA0;1&#XA0;&#X2212;&#XA0;</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>Var</I>(&#X3B5;)</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>Var</I>(<I>Y</I>)</TD></TR>
</TABLE></TD></TR>
</TABLE><P>
To understand what <I>R</I><SUP>2</SUP> means, suppose (again) that you are trying
to guess someone&#X2019;s weight. If you didn&#X2019;t know anything about them,
your best strategy would be to guess &#X233;; in
that case the MSE of your guesses would be Var(<I>Y</I>):
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><I>MSE</I>&#XA0;=&#XA0;</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
</TABLE></TD><TD CLASS="dcell">&#XA0;<FONT SIZE=6>&#X2211;</FONT>(&#X233;&#XA0;&#X2212;&#XA0;<I>y<SUB>i</SUB></I>)<SUP>2</SUP>&#XA0;=&#XA0;<I>Var</I>(<I>Y</I>)&#XA0;</TD></TR>
</TABLE><P>
But if I told you their height, you would guess &#X3B1; +
&#X3B2; <I>x<SUB>i</SUB></I>; in that case your MSE would be Var(&#X3B5;).
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><I>MSE</I>&#XA0;=&#XA0;
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
</TABLE></TD><TD CLASS="dcell">&#XA0;<FONT SIZE=6>&#X2211;</FONT>(&#X3B1;&#XA0;+&#XA0;&#X3B2;&#XA0;<I>x<SUB>i</SUB></I>&#XA0;&#X2212;&#XA0;<I>y<SUB>i</SUB></I>)<SUP>2</SUP>&#XA0;=
<I>Var</I>(&#X3B5;)&#XA0;</TD></TR>
</TABLE><P>
So the term Var(&#X3B5;)/Var(<I>Y</I>) is the ratio of mean squared error with
and without the explanatory variable, which is the fraction of
variability left unexplained by the model. The complement, <I>R</I><SUP>2</SUP>,
is the fraction of variability explained by the model.
<A NAME="@default1063"></A></P><P>If a model yields <I>R</I><SUP>2</SUP>&#XA0;=&#XA0;0.64, you could say that the model explains
64% of the variability, or it might be more precise to say that it
reduces the MSE of your predictions by 64%.</P><P>In the context of a linear least squares model, it turns out that
there is a simple relationship between the coefficient of
determination and Pearson&#X2019;s correlation coefficient, &#X3C1;:</P><P>&#XA0;&#XA0; <I>R</I><SUP>2</SUP> = &#X3C1;<SUP>2</SUP> </P><P>See <TT>http://wikipedia.org/wiki/Howzzat</TT>!
<A NAME="@default1064"></A></P><DIV CLASS="theorem"><B>Exercise&#XA0;8</B>&#XA0;&#XA0;<EM>
The Wechsler Adult Intelligence Scale (WAIS) is meant to be a measure
of intelligence; scores are calibrated so that the mean and standard
deviation in the general population are 100 and 15.
</EM><A NAME="@default1065"></A>
<A NAME="@default1066"></A>
<A NAME="@default1067"></A>
<A NAME="@default1068"></A><P><EM>Suppose that you wanted to predict someone&#X2019;s WAIS score based on their
SAT scores. According to one study, there is a Pearson correlation of
0.72 between total SAT scores and WAIS scores.</EM></P><P><EM>If you applied your predictor to a large sample, what would you expect to
be the mean squared error (MSE) of your predictions?</EM></P><P><EM>Hint: What is the MSE if you always guess 100?
</EM></P></DIV><DIV CLASS="theorem"><B>Exercise&#XA0;9</B>&#XA0;&#XA0;<EM>
Write a function named <TT>Residuals</TT> that takes <I>X</I>, <I>Y</I>, &#X3B1;
and &#X3B2; and returns a list of &#X3B5;<SUB><I>i</I></SUB>.
</EM><A NAME="@default1069"></A><P><EM>Write a function named <TT>CoefDetermination</TT> that takes the 
&#X3B5;<SUB><I>i</I></SUB>&#XA0;and <I>Y</I>&#XA0;and returns <I>R</I><SUP>2</SUP>. To test your functions, 
confirm that <I>R</I><SUP>2</SUP>&#XA0;=&#XA0;&#X3C1;<SUP>2</SUP>. You can download a solution
from <TT>http://thinkstats.com/correlation.py</TT>.
</EM><A NAME="@default1070"></A></P></DIV><DIV CLASS="theorem"><B>Exercise&#XA0;10</B>&#XA0;&#XA0;<EM>
Using the height and weight data from the BRFSS (one more time),
compute &#X3B1;, &#X3B2; and <I>R</I><SUP>2</SUP>. If you were trying to guess
someone&#X2019;s weight, how much would it help to know their height?
You can download a solution from
<TT>http://thinkstats.com/brfss_corr.py</TT>.
</EM><A NAME="@default1071"></A>
<A NAME="@default1072"></A>
<A NAME="@default1073"></A></DIV><H2 CLASS="section"><A NAME="toc84"></A><A NAME="htoc91">9.8</A>&#XA0;&#XA0;Correlation and Causation</H2><P>
<A NAME="@default1074"></A>
<A NAME="@default1075"></A>
<A NAME="@default1076"></A>
<A NAME="@default1077"></A>
<A NAME="@default1078"></A></P><P>The web comic <TT>xkcd</TT> demonstrates the difficulty of inferring
causation:</P><BLOCKQUOTE CLASS="figure"><DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV>
<DIV CLASS="center"><IMG SRC="thinkstats023.png"></DIV>
<DIV CLASS="caption"><TABLE CELLSPACING=6 CELLPADDING=0><TR><TD VALIGN=top ALIGN=left>Figure 9.6: From <TT>xkcd.com</TT> by Randall Munroe.</TD></TR>
</TABLE></DIV>
<DIV CLASS="center"><HR WIDTH="80%" SIZE=2></DIV></BLOCKQUOTE><P>In general, a relationship between two variables does not tell you
whether one causes the other, or the other way around, or both, or
whether they might both be caused by something else altogether.</P><P>This rule can be summarized with the phrase &#X201C;Correlation
does not imply causation,&#X201D; which is so pithy it has its own
Wikipedia page: <TT>http://wikipedia.org/wiki/Correlation_does_not_imply_causation</TT>.</P><P>So what can you do to provide evidence of causation?</P><OL CLASS="enumerate" type=1><LI CLASS="li-enumerate">Use time. If A comes before B, then A can cause B but not the
other way around (at least according to our common understanding of
causation). The order of events can help us infer the direction
of causation, but it does not preclude the possibility that something
else causes both A and B.</LI><LI CLASS="li-enumerate">Use randomness. If you divide a large population into two
groups at random and compute the means of almost any variable, you
expect the difference to be small. This is a consequence of the
Central Limit Theorem (so it is subject to the same requirements).<P>If the groups are nearly identical in all variable but one, you
can eliminate spurious relationships.
<A NAME="@default1079"></A></P><P>This works even if you don&#X2019;t know what the relevant variables
are, but it works even better if you do, because you can check that
the groups are identical.</P></LI></OL><P>These ideas are the motivation for the <B>randomized controlled
trial</B>, in which subjects are assigned randomly to two (or more)
groups: a <B>treatment</B> group that receives some kind of intervention,
like a new medicine, and a <B>control group</B> that receives
no intervention, or another treatment whose effects are known.
<A NAME="@default1080"></A>
<A NAME="@default1081"></A>
<A NAME="@default1082"></A>
<A NAME="@default1083"></A>
<A NAME="@default1084"></A></P><P>A randomized controlled trial is the most reliable way to demonstrate
a causal relationship, and the foundation of science-based medicine
(see <TT>http://wikipedia.org/wiki/Randomized_controlled_trial</TT>).</P><P>Unfortunately, controlled trials are only possible in the laboratory
sciences, medicine, and a few other disciplines. In the social sciences,
controlled experiments are rare, usually because they are impossible
or unethical.</P><P>One alternative is to look for a <B>natural experiment</B>, where
different &#X201C;treatments&#X201D; are applied to groups that are otherwise
similar. One danger of natural experiments is that the groups might
differ in ways that are not apparent. You can read more about this
topic at <TT>http://wikipedia.org/wiki/Natural_experiment</TT>.
<A NAME="@default1085"></A></P><P>In some cases it is possible to infer causal relationships using <B>regression analysis</B>. A linear least squares fit
is a simple form of regression that explains a dependent
variable using one explanatory variable. There are similar
techniques that work with arbitrary numbers of independent variables.
<A NAME="@default1086"></A></P><P>I won&#X2019;t cover those techniques here, but there are also simple ways to
control for spurious relationships. For example, in the NSFG, we saw
that first babies tend to be lighter than others (see
Section&#XA0;<A HREF="thinkstats004.html#birth_weights">3.6</A>). But birth weight is also correlated
with the mother&#X2019;s age, and mothers of first babies tend to be younger
than mothers of other babies.
<A NAME="@default1087"></A>
<A NAME="@default1088"></A>
<A NAME="@default1089"></A>
<A NAME="@default1090"></A></P><P>So it may be that first babies are lighter because their mothers are
younger. To control for the effect of age, we could divide the mothers
into age groups and compare birth weights for first babies and others
in each age group.
<A NAME="@default1091"></A></P><P>If the difference between first babies and others is the same in
each age group as it was in the pooled data, we conclude
that the difference is not related to age. If there is no difference,
we conclude that the effect is entirely due to age. Or,
if the difference is smaller, we can quantify how much of the effect
is due to age.</P><DIV CLASS="theorem"><B>Exercise&#XA0;11</B>&#XA0;&#XA0;<EM>
The NSFG data includes a variable named <TT>agepreg</TT> that records
the age of the mother at the time of birth.
Make a scatterplot of mother&#X2019;s age and baby&#X2019;s weight for each live
birth. Can you see a relationship?</EM><P><EM>Compute a linear least-squares fit for these variables. What are the
units of the estimated parameters &#X3B1; and &#X3B2;?
How would you summarize these results in a sentence or two?</EM></P><P><EM>Compute the average age for mothers of first babies and the average
age of other mothers. Based on the difference in ages between the
groups, how much difference do you expect in the mean birth weights?
What fraction of the actual difference in birth weights is explained
by the difference in ages?</EM></P><P><EM>You can download a solution to this problem from
<TT>http://thinkstats.com/agemodel.py</TT>. If you are curious about
multivariate regression, you can run <TT>http://thinkstats.com/age_lm.py</TT>
which shows how to use the R statistical computing package from
Python. But that&#X2019;s a whole other book.
</EM><A NAME="@default1092"></A>
<A NAME="@default1093"></A></P></DIV><H2 CLASS="section"><A NAME="toc85"></A><A NAME="htoc92">9.9</A>&#XA0;&#XA0;Glossary</H2><DL CLASS="description"><DT CLASS="dt-description"><B>correlation:</B></DT><DD CLASS="dd-description"> a description of the dependence between variables.
<A NAME="@default1094"></A></DD><DT CLASS="dt-description"><B>normalize:</B></DT><DD CLASS="dd-description"> To transform a set of values so that their mean is 0 and
their variance is 1.
<A NAME="@default1095"></A></DD><DT CLASS="dt-description"><B>standard score:</B></DT><DD CLASS="dd-description"> A value that has been normalized.
<A NAME="@default1096"></A></DD><DT CLASS="dt-description"><B>covariance:</B></DT><DD CLASS="dd-description"> a measure of the tendency of two variables
to vary together.
<A NAME="@default1097"></A></DD><DT CLASS="dt-description"><B>rank:</B></DT><DD CLASS="dd-description"> The index where an element appears in a sorted list.
<A NAME="@default1098"></A></DD><DT CLASS="dt-description"><B>least squares fit:</B></DT><DD CLASS="dd-description"> A model of a dataset that minimizes the
sum of squares of the residuals.
<A NAME="@default1099"></A></DD><DT CLASS="dt-description"><B>residual:</B></DT><DD CLASS="dd-description"> A measure of the deviation of an actual value from a model.
<A NAME="@default1100"></A></DD><DT CLASS="dt-description"><B>dependent variable:</B></DT><DD CLASS="dd-description"> A variable we are trying to predict or explain.
<A NAME="@default1101"></A></DD><DT CLASS="dt-description"><B>independent variable:</B></DT><DD CLASS="dd-description"> A variable we are using to predict a dependent
variable, also called an explanatory variable.
<A NAME="@default1102"></A></DD><DT CLASS="dt-description"><B>coefficient of determination:</B></DT><DD CLASS="dd-description"> A measure of the goodness of fit
of a linear model.
<A NAME="@default1103"></A></DD><DT CLASS="dt-description"><B>randomized controlled trial:</B></DT><DD CLASS="dd-description"> An experimental design in which subject
are divided into groups at random, and different groups are given different
treatments.
<A NAME="@default1104"></A></DD><DT CLASS="dt-description"><B>treatment:</B></DT><DD CLASS="dd-description"> An change or intervention applied to one group in a
controlled trial.
<A NAME="@default1105"></A></DD><DT CLASS="dt-description"><B>control group:</B></DT><DD CLASS="dd-description"> A group in a controlled trial that receives no
treatment, or a treatment whose effect is known.
<A NAME="@default1106"></A></DD><DT CLASS="dt-description"><B>natural experiment:</B></DT><DD CLASS="dd-description"> An experimental design that takes advantage of
a natural division of subjects into groups in ways that are at least
approximately random.
<A NAME="@default1107"></A></DD></DL><HR CLASS="footnoterule"><DL CLASS="thefootnotes"><DT CLASS="dt-thefootnotes">
<A NAME="note26" HREF="#text26">1</A></DT><DD CLASS="dd-thefootnotes">See
<TT>http://wikipedia.org/wiki/Simple_linear_regression</TT>.
</DD><DT CLASS="dt-thefootnotes"><A NAME="note27" HREF="#text27">2</A></DT><DD CLASS="dd-thefootnotes">See Press et al., <EM>Numerical Recipes in C</EM>,
Chapter 15 at <TT>http://www.nrbook.com/a/bookcpdf/c15-1.pdf</TT>.
</DD></DL>
</td>

<td width=130 valign="top">

<h4>Like this book?</h4> <iframe src="http://www.facebook.com/plugins/likebox.php?href=http%3A%2F%2Fwww.facebook.com%2Fpages%2FThink-Stats%2F181213931900328&amp;width=130&amp;colorscheme=light&amp;show_faces=false&amp;stream=false&amp;header=false&amp;height=62" scrolling="no" frameborder="0" style="border:none; overflow:hidden; width:130px; height:100px;" allowTransparency="true"></iframe>

<p>
<h4>Are you using one of our books in a class?</h4>  We'd like to know
about it.  Please consider filling out <a href="http://spreadsheets.google.com/viewform?formkey=dC0tNUZkMjBEdXVoRGljNm9FRmlTMHc6MA" onClick="javascript: pageTracker._trackPageview('/outbound/survey');">this short survey</a>.

<p>
<br>

<p>
<iframe src="http://rcm.amazon.com/e/cm?t=greenteapre01-20&o=1&p=8&l=as1&asins=1
449307116&ref=qf_sp_asin_til&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1
=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" margi
nwidth="0" marginheight="0" frameborder="0"></iframe>

<p>
<iframe src="http://rcm.amazon.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=greenteapre01-20&o=1&p=8&l=as1&m=amazon&f=ifr&md=10FE9736YVPPT7A0FBG2&asins=0521725968" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" onClick="javascript: pageTracker._trackPageview('/outbound/amazon');"></iframe>

<p>
<iframe src="http://rcm.amazon.com/e/cm?t=greenteapre01-20&o=1&p=8&l=as1&asins=0615185509&fc1=000000&IS2=1&lt1=_blank&m=amazon&lc1=0000FF&bc1=000000&bg1=FFFFFF&f=ifr" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" onClick="javascript: pageTracker._trackPageview('/outbound/amazon_matlab');"></iframe> 

</td>
</tr>
</table>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-9267613-1");
pageTracker._trackPageview();
} catch(err) {}</script>
</body>
<HR>
<A HREF="thinkstats009.html"><IMG SRC="back.png" ALT="Previous"></A>
<A HREF="index.html"><IMG SRC="up.png" ALT="Up"></A>
<A HREF="thinkstats011.html"><IMG SRC="next.png" ALT="Next"></A>
</BODY>
</HTML>
